# FindHappy 一起挖掘幸福感
数据挖掘课程最终项目——一起挖掘幸福感

小组成员：杨毅哲、田雄辉、张雨婷、李安腾、王梓屹

项目结构如下：

```shell
├── DLMethods
│   ├── blocks.py
│   ├── data_generator.py
│   ├── experiments.conf
│   ├── model.py
│   ├── resnet.py
│   ├── test.py
│   ├── train.py
│   ├── trainer.py
│   ├── utils.py
│   └── visualize.py
├── FinalReport.pdf
├── MLMethods.py
├── README.md
├── TextClassifier
│   ├── main.py
│   └── template.py
├── preprocess.py
└── visualization.py
```

## 环境配置

* python>=3.6
* pytorch>=1.6.0
* pyhocon
* numpy
* pandas
* imblearn
* transformers==4.6.0

## 数据处理

### 数据预处理

数据预处理阶段主要对训练集和测试集的数据进行预处理，包括对缺失值、异常值的处理，数据类型转换和数据分箱、归一化处理等

代码文件：`preprocess.py`

### 数据可视化

在预处理的基础上对数据中有代表性的属性进行可视化处理，可视化手段包括直方图，盒图，饼图，条状图等，利于分析各属性之间的相关性。

代码文件：`visualizaiton.py`

## 挖掘分析

### 机器学习方法

为降低后续建模的复杂度，减少冗余的信息，对预处理后的数据集进行特征筛选，包括画热力图看特征之间、特征与预测目标之间的相关性，利用树模型进行特征筛选等。

代码文件：`MLMethods.py`

### 神经网络方法

根据数据分析阶段和预处理阶段的结果，使用特征筛选得到的特征作为模型的输入，对模型进行训练、验证和测试，并输出在测试集上的预测结果。
本项目实现了多层感知机和深度残差网络两种神经网络模型，并实现了深度残差网络的改进模型: 深度残差收缩网络，用以减弱数据噪声的影响。

代码文件：`DLMethods/`

运行方法：

* 根据需要修改`src/experiments.conf`中的配置项;
* 修改`src/train.py`中读取的配置名称;
* 运行`src/train.py`或执行`train.sh`脚本。

### 文本分类方法

除了多层感知机网络和残差网络直接将收集到的数据建模称为特征的方法，我们还采用了基于语义进行文本分类的神经网络方法。

我们设计采用文本分类的方法代替直接特征提取的原因在于：早期的机器学习方法或神经网络方法都需要人类手动地提取特征，而本次实验中收集到的数据就是我们所需要的特征，但是近年来深度神经网络和大规模预训练模型快速发展，使得神经网络模型可以从文本原始数据中提取到更加合适的特征信息。为了利用这种信息，我们决定将特征还原回原始文本，这样不仅可以将离散的特征数据变成具有语义可解释的文本数据，而且有利于模型从中提取出更适合模型的特征。

代码文件：`TextClasifier/`

运行方法：

- 运行`template.py`文件，将特征数据转换为文本数据
- 运行`main.py`文件进行训练

更多具体内容和结果的详细信息展示于`FinalReport.pdf`中
